{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all dependencies\n",
    "from __future__ import print_function\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import CSVLogger\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define constants\n",
    "pickle_file = '../dataset/SVHN_multi.pickle'\n",
    "image_size = 32\n",
    "num_labels = 11 # 0-9, + blank \n",
    "num_channels = 3 # grayscale with x,y pos\n",
    "\n",
    "batch_size = 64\n",
    "patch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx, ny = (image_size, image_size)\n",
    "xt = np.linspace(0, 1, nx)\n",
    "yt = np.linspace(0, 1, ny)\n",
    "xpos, ypos = np.meshgrid(xt, yt)\n",
    "\n",
    "def pre_processing(images):\n",
    "    processed_images = []\n",
    "    for image in images:\n",
    "        # print(image.shape)\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = np.reshape(image, (image_size,image_size))\n",
    "        asd = np.swapaxes(np.swapaxes(np.array(np.concatenate([[image], [xpos], [ypos]])), 0, 1), 1, 2)\n",
    "        # resized = cv2.resize(asd, (32, 32, 3), interpolation = cv2.INTER_CUBIC)\n",
    "        processed_images.append(asd)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "def label_processing(labels):\n",
    "    processed_labels = []\n",
    "    for label in labels:\n",
    "        # new_label = []\n",
    "        # for i in range(6):\n",
    "            # test = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "            # test[label[i]] = 1\n",
    "            # new_label.append(test)\n",
    "        # processed_labels.append(np.array(new_label, ndmin=2))\n",
    "        processed_labels.append(label[5]*100000+label[4]*10000+label[3]*1000+label[2]*100+label[1]*10+label[0])\n",
    "    return np.array(processed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/SVHN_multi.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bfdaa3c464f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# loading data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../dataset/SVHN_multi.pickle'"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = pre_processing(save['train_dataset'])\n",
    "    train_labels = label_processing(save['train_labels'])\n",
    "    valid_dataset = pre_processing(save['valid_dataset'])\n",
    "    valid_labels = label_processing(save['valid_labels'])\n",
    "    test_dataset = pre_processing(save['test_dataset'])\n",
    "    test_labels = label_processing(save['test_labels'])\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load VGG16\n",
    "model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
    "model_vgg16_conv.summary()\n",
    "\n",
    "img_input = Input(shape=(image_size, image_size, num_channels), name = 'image_input')\n",
    "output_vgg16_conv = model_vgg16_conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attention based modelling\n",
    "\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "d0 = Dense(4096, activation='relu', name='numDigitsfc1')(x)\n",
    "d0 = Dense(1024, activation='relu', name='numDigitsfc2')(d0)\n",
    "d0 = Dense(11, activation='softmax', name='numDigits')(d0)\n",
    "\n",
    "d1 = Dense(4096, activation='relu', name='d1fc1')(x)\n",
    "d1 = Dense(1024, activation='relu', name='d1fc2')(d1)\n",
    "d1 = Dense(11, activation='softmax', name='d1pred')(d1)\n",
    "\n",
    "d2 = Dense(4096, activation='relu', name='d2fc1')(x)\n",
    "d2 = Dense(1024, activation='relu', name='d2fc2')(d2)\n",
    "d2 = Dense(11, activation='softmax', name='d2pred')(d2)\n",
    "\n",
    "d3 = Dense(4096, activation='relu', name='d3fc1')(x)\n",
    "d3 = Dense(1024, activation='relu', name='d3fc2')(d3)\n",
    "d3 = Dense(11, activation='softmax', name='d3pred')(d3)\n",
    "\n",
    "d4 = Dense(4096, activation='relu', name='d4fc1')(x)\n",
    "d4 = Dense(1024, activation='relu', name='d4fc2')(d4)\n",
    "d4 = Dense(11, activation='softmax', name='d4pred')(d4)\n",
    "\n",
    "d5 = Dense(4096, activation='relu', name='d5fc1')(x)\n",
    "d5 = Dense(1024, activation='relu', name='d5fc2')(d5)\n",
    "d5 = Dense(11, activation='softmax', name='d5pred')(d5)\n",
    "\n",
    "digits = [K.argmax(d0,1), K.argmax(d1,1), K.argmax(d2,1), K.argmax(d3,1), K.argmax(d4,1), K.argmax(d5,1)]\n",
    "# digits = [digit for digit in digits if digit[0] != 10] # how to comapre keras_tensor with integer\n",
    "predicted_output = digits[5]*100000 + digits[4]*10000 + digits[3]*1000 + digits[2]*100 + digits[1]*10 + digits[0] \n",
    "model = Model(input=img_input, output=predicted_output)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create directory\n",
    "if not os.path.exists(\"..results\"):\n",
    "    os.mkdir(\"../results\")\n",
    "    os.mkdir(\"../results/best_models\")\n",
    "    os.mkdir(\"../results/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# callback functions\n",
    "checkpointer = ModelCheckpoint(filepath=\"../results/best_models/fn_model.{epoch:02d}-{val_acc:.6f}.hdf5\", verbose=1, monitor='val_acc', save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "tf_board = TensorBoard(log_dir='../results/logs', histogram_freq=100, write_graph=True, write_grads:True, write_images=True)\n",
    "csv_logger = CSVLogger('../results/training.log')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing model\n",
    "model.fit(train_dataset, train_labels, batch_size=batch_size, nb_epoch=250, validation_data=(valid_dataset, valid_labels), callbacks=[checkpointer, tf_board, csv_logger, early_stopping])\n",
    "model.save(\"../results/final_svhn.hdf5\")\n",
    "score, acc = model.evaluate(test_dataset, test_labels, batch_size=batch_size)\n",
    "resultsfile = open(\"../results/results.txt\", 'w')\n",
    "resultsfile.write(\"test_acc: \"+str(acc)+ \"\\n\")\n",
    "resultsfile.write(\"test_score: \"+str(score))\n",
    "resultsfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
